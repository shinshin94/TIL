# 크롤링

# BeautifulSoup

> * `pip install beautifulsoup4`을 가상환경에 인스톨해줍니다
>
> * 사용시
>
>   * ```
>     from bs4 import BeautifulSoup	#인스톨한걸 사용선언
>     import urllib.request		#서버에 요청합니다.
>     ```
>
>   * ```
>     resp = urllib.request.urlopen('자신이 크롤링할 url주소')
>     ```
>
>   * ```
>     soup = BeautifulSoup(resp, 'html.parser')
>     #BeatifulSoup를 이용하여 앞서 받아온 객체(resp)를 html의 parser로 변환해줍니다.
>     ```
>
>   * ```
>     x = soup.find_all('dl',class_ ='해당 url에 중복되는 클래스명')
>     ```

# selenium

> * 자동화라는 뜻입니다
>
> * webdriver를 같이 자주 사용합니다.(설치 크롬 검색 `webdriver`)
>
> * ```
>   from selenium import webdriver		#웹드라이버를 이용
>   from selenium.webdriver.common.by import By	#웹드라이버를 사용하는데 공통적인것중에 by를 import
>   from time import sleep		#웨이팅 타임 지정
>   ```
>
> * ```
>   service = webdriver.chrome.service.Service('드라이버 위치/chromedriver.exe')
>   driver = webdriver.Chrome(service=service)
>   #2022/02/10기준 최신 버젼에서는 service를 직접 지정해줘야 합니다
>   ```
>
> * ```
>   driver.get('자동화 실행할 url주소')
>   sleep(5)	#5초의 기다림을 주겠다
>   ```
>
> * ```
>   id= driver.find_element(By.NAME,"해당 url에서 해당할 name 부분의 이름")
>   id.send_keys(input_id)
>   #드라이버를 사용해서 해당 name 부분에 send_keys로 인풋으로 입력할 id를 줄겁니다
>   pw = driver.find_element(By.NAME,"password")
>   pw.send_keys(input_pw)
>   sleep(2)
>   #드라이버를 사용해서 해당 name 부분에 send_keys로 인풋으로 입력할 pw를 줄겁니다 그리고 2초의 기다림을 줍니다
>   ```
>
> * ```
>   driver.find_element(By.CSS_SELECTOR,"해당하는곳의 id나  클릭할 위치를 지정합니다").click()
>   sleep(2)
>   driver.refresh()
>   #id와 pw를 입력한뒤 클릭할 곳을 지정해주고 2초의 기다림을 줍니다.
>   refresh로 새로고침
>   ```

